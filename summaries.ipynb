{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a580b6a6-4b68-4e08-9050-edce504ccbbb",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85ad66f2-7380-43b4-94f9-0d095580cabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e21e395e-f91a-441a-8982-fa2090bb05b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in ./venv/lib/python3.11/site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in ./venv/lib/python3.11/site-packages (4.13.3)\n",
      "Requirement already satisfied: google-generativeai in ./venv/lib/python3.11/site-packages (0.8.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.11/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.11/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.11/site-packages (from requests) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.11/site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./venv/lib/python3.11/site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in ./venv/lib/python3.11/site-packages (from beautifulsoup4) (4.13.2)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in ./venv/lib/python3.11/site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in ./venv/lib/python3.11/site-packages (from google-generativeai) (2.24.2)\n",
      "Requirement already satisfied: google-api-python-client in ./venv/lib/python3.11/site-packages (from google-generativeai) (2.166.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in ./venv/lib/python3.11/site-packages (from google-generativeai) (2.38.0)\n",
      "Requirement already satisfied: protobuf in ./venv/lib/python3.11/site-packages (from google-generativeai) (5.29.4)\n",
      "Requirement already satisfied: pydantic in ./venv/lib/python3.11/site-packages (from google-generativeai) (2.11.3)\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.11/site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in ./venv/lib/python3.11/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./venv/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./venv/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./venv/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in ./venv/lib/python3.11/site-packages (from google-api-core->google-generativeai) (1.69.2)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in ./venv/lib/python3.11/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in ./venv/lib/python3.11/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in ./venv/lib/python3.11/site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.11/site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in ./venv/lib/python3.11/site-packages (from pydantic->google-generativeai) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./venv/lib/python3.11/site-packages (from pydantic->google-generativeai) (0.4.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in ./venv/lib/python3.11/site-packages (from google-api-core->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in ./venv/lib/python3.11/site-packages (from google-api-core->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in ./venv/lib/python3.11/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in ./venv/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install requests beautifulsoup4 google-generativeai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3c02cb-5b7a-4e85-bba0-a705c80f4ed3",
   "metadata": {},
   "source": [
    "# Connecting to OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5929fc4-5246-4bde-8a61-fa3d459b25c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-proj-8\n",
      "AIz\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "print(api_key[:9])\n",
    "gemini_api_key = os.getenv('GEMINI_API_KEY')\n",
    "print(gemini_api_key[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdd1314e-66f1-4cca-85aa-8375dbea7dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()\n",
    "gemini = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9e29bdc-32a0-4b02-8622-5f9ec7c9f297",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd69caef-fce5-49bf-9c2a-728543aa5b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI Research | OpenAI\n",
      "Skip to main content\n",
      "Log in\n",
      "Switch to\n",
      "ChatGPT\n",
      "(opens in a new window)\n",
      "Sora\n",
      "(opens in a new window)\n",
      "API Platform\n",
      "(opens in a new window)\n",
      "Home\n",
      "Research Index\n",
      "Research Overview\n",
      "Research Residency\n",
      "Latest Advancements\n",
      "GPT-4.5\n",
      "OpenAI o3-mini\n",
      "OpenAI o1\n",
      "OpenAI o1-mini\n",
      "GPT-4o\n",
      "GPT-4o mini\n",
      "Sora\n",
      "Research\n",
      "Back to main menu\n",
      "Research Index\n",
      "Research Overview\n",
      "Research Residency\n",
      "Latest Advancements\n",
      "GPT-4.5\n",
      "OpenAI o3-mini\n",
      "OpenAI o1\n",
      "OpenAI o1-mini\n",
      "GPT-4o\n",
      "GPT-4o mini\n",
      "Sora\n",
      "Safety\n",
      "Back to main menu\n",
      "Safety Approach\n",
      "Security & Privacy\n",
      "ChatGPT\n",
      "Back to main menu\n",
      "Explore ChatGPT\n",
      "Team\n",
      "Enterprise\n",
      "Education\n",
      "Pricing\n",
      "Download\n",
      "Sora\n",
      "Back to main menu\n",
      "Sora Overview\n",
      "Features\n",
      "Pricing\n",
      "Help center\n",
      "(opens in a new window)\n",
      "Sora log in\n",
      "(opens in a new window)\n",
      "API Platform\n",
      "Back to main menu\n",
      "Platform Overview\n",
      "Pricing\n",
      "API Log in\n",
      "(opens in a new window)\n",
      "Documentation\n",
      "(opens in a new window)\n",
      "Developer Forum\n",
      "(opens in a new window)\n",
      "For Business\n",
      "Stories\n",
      "Company\n",
      "Back to main menu\n",
      "About us\n",
      "Our Charter\n",
      "Careers\n",
      "Brand\n",
      "Overview\n",
      "Logos\n",
      "Gallery\n",
      "Partnerships\n",
      "Typography\n",
      "Language\n",
      "Contact\n",
      "News\n",
      "Log in\n",
      "OpenAI\n",
      "Research\n",
      "All\n",
      "Publication\n",
      "Conclusion\n",
      "Milestone\n",
      "Release\n",
      "Filter\n",
      "Sort\n",
      "Switch cards to show Media\n",
      "Switch cards to hide Media\n",
      "Publication\n",
      "Apr 10, 2025\n",
      "BrowseComp: a benchmark for browsing agents\n",
      "BrowseComp: a benchmark for browsing agents.\n",
      "Publication\n",
      "Apr 2, 2025\n",
      "PaperBench: Evaluating AI’s Ability to Replicate AI Research\n",
      "We introduce PaperBench, a benchmark evaluating the ability of AI agents to replicate state-of-the-art AI research.\n",
      "Product\n",
      "Mar 25, 2025\n",
      "Introducing 4o Image Generation\n",
      "At OpenAI, we have long believed image generation should be a primary capability of our language models. That’s why we’ve built our most advanced image generator yet into GPT‑4o. The result—image generation that is not only beautiful, but useful.\n",
      "Publication\n",
      "Mar 25, 2025\n",
      "Addendum to GPT-4o System Card: 4o image generation\n",
      "4o image generation is a new, significantly more capable image generation approach than our earlier DALL·E 3 series of models. It can create photorealistic output. It can take images as inputs and transform them.\n",
      "Research\n",
      "Mar 21, 2025\n",
      "Early methods for studying affective use and emotional well-being on ChatGPT\n",
      "An OpenAI and MIT Media Lab Research collaboration.\n",
      "Release\n",
      "Mar 20, 2025\n",
      "Introducing next-generation audio models in the API\n",
      "For the first time, developers can also instruct the text-to-speech model to speak in a specific way—for example, “talk like a sympathetic customer service agent”—unlocking a new level of customization for voice agents.\n",
      "Publication\n",
      "Mar 10, 2025\n",
      "Detecting misbehavior in frontier reasoning models\n",
      "Frontier reasoning models exploit loopholes when given the chance. We show we can detect exploits using an LLM to monitor their chains-of-thought. Penalizing their “bad thoughts” doesn’t stop the majority of misbehavior—it makes them hide their intent.\n",
      "Publication\n",
      "Feb 27, 2025\n",
      "OpenAI GPT-4.5 System Card\n",
      "We’re releasing a research preview of OpenAI GPT‑4.5, our largest and most knowledgeable model yet.\n",
      "Release\n",
      "Feb 27, 2025\n",
      "Introducing GPT-4.5\n",
      "We’re releasing a research preview of GPT‑4.5—our largest and best model for chat yet. GPT‑4.5 is a step forward in scaling up pre-training and post-training.\n",
      "Load more\n",
      "Our Research\n",
      "Research Index\n",
      "Research Overview\n",
      "Research Residency\n",
      "Latest Advancements\n",
      "OpenAI o1\n",
      "OpenAI o1-mini\n",
      "GPT-4o\n",
      "GPT-4o mini\n",
      "Sora\n",
      "Safety\n",
      "Safety Approach\n",
      "Security & Privacy\n",
      "ChatGPT\n",
      "Explore ChatGPT\n",
      "Team\n",
      "Enterprise\n",
      "Education\n",
      "Pricing\n",
      "Download\n",
      "Sora\n",
      "Sora Overview\n",
      "Features\n",
      "Pricing\n",
      "Sora log in\n",
      "(opens in a new window)\n",
      "API Platform\n",
      "Platform Overview\n",
      "Pricing\n",
      "API log in\n",
      "(opens in a new window)\n",
      "Documentation\n",
      "(opens in a new window)\n",
      "Developer Forum\n",
      "(opens in a new window)\n",
      "For Business\n",
      "Overview\n",
      "Company\n",
      "About us\n",
      "Our Charter\n",
      "Careers\n",
      "Brand\n",
      "More\n",
      "News\n",
      "Stories\n",
      "Help Center\n",
      "(opens in a new window)\n",
      "Terms & Policies\n",
      "Terms of Use\n",
      "Privacy Policy\n",
      "Security\n",
      "Other Policies\n",
      "(opens in a new window)\n",
      "(opens in a new window)\n",
      "(opens in a new window)\n",
      "(opens in a new window)\n",
      "(opens in a new window)\n",
      "(opens in a new window)\n",
      "(opens in a new window)\n",
      "OpenAI © 2015–2025\n"
     ]
    }
   ],
   "source": [
    "summary = Website(\"https://openai.com/research/index/\")\n",
    "print(summary.title)\n",
    "print(summary.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a406fe1-49a7-4e15-ae36-5f7bb1448e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You're an AI assistant and your role is to provide short and informative summary of webistes provided to you. Response in Markdown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8757256-d4de-464a-847c-14de3c02aefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_prompt(website):\n",
    "    user_prompt = f\"You are looking at a website titled{website.title}\"\n",
    "    user_prompt += \"The content of the website is provided below. Please summarize all the necessary things\\\n",
    "                    provided. Also summarize any images, links or any other texts if required.\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106381e4-d36b-4e57-a11d-9f012802c910",
   "metadata": {},
   "source": [
    "# API format for OpenAI\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message goes here\"},\n",
    "    {\"role\": \"user\", \"content\": \"user message goes here\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc696ed6-65f5-49cb-8e42-f69e1cbd7227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8aaedbad-529a-4007-81c5-9fb000f492d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"You're an AI assistant and your role is to provide short and informative summary of webistes provided to you. Response in Markdown\"},\n",
       " {'role': 'user',\n",
       "  'content': 'You are looking at a website titledOpenAI Research | OpenAIThe content of the website is provided below. Please summarize all the necessary things                    provided. Also summarize any images, links or any other texts if required.Skip to main content\\nLog in\\nSwitch to\\nChatGPT\\n(opens in a new window)\\nSora\\n(opens in a new window)\\nAPI Platform\\n(opens in a new window)\\nHome\\nResearch Index\\nResearch Overview\\nResearch Residency\\nLatest Advancements\\nGPT-4.5\\nOpenAI o3-mini\\nOpenAI o1\\nOpenAI o1-mini\\nGPT-4o\\nGPT-4o mini\\nSora\\nResearch\\nBack to main menu\\nResearch Index\\nResearch Overview\\nResearch Residency\\nLatest Advancements\\nGPT-4.5\\nOpenAI o3-mini\\nOpenAI o1\\nOpenAI o1-mini\\nGPT-4o\\nGPT-4o mini\\nSora\\nSafety\\nBack to main menu\\nSafety Approach\\nSecurity & Privacy\\nChatGPT\\nBack to main menu\\nExplore ChatGPT\\nTeam\\nEnterprise\\nEducation\\nPricing\\nDownload\\nSora\\nBack to main menu\\nSora Overview\\nFeatures\\nPricing\\nHelp center\\n(opens in a new window)\\nSora log in\\n(opens in a new window)\\nAPI Platform\\nBack to main menu\\nPlatform Overview\\nPricing\\nAPI Log in\\n(opens in a new window)\\nDocumentation\\n(opens in a new window)\\nDeveloper Forum\\n(opens in a new window)\\nFor Business\\nStories\\nCompany\\nBack to main menu\\nAbout us\\nOur Charter\\nCareers\\nBrand\\nOverview\\nLogos\\nGallery\\nPartnerships\\nTypography\\nLanguage\\nContact\\nNews\\nLog in\\nOpenAI\\nResearch\\nAll\\nPublication\\nConclusion\\nMilestone\\nRelease\\nFilter\\nSort\\nSwitch cards to show Media\\nSwitch cards to hide Media\\nPublication\\nApr 10, 2025\\nBrowseComp: a benchmark for browsing agents\\nBrowseComp: a benchmark for browsing agents.\\nPublication\\nApr 2, 2025\\nPaperBench: Evaluating AI’s Ability to Replicate AI Research\\nWe introduce PaperBench, a benchmark evaluating the ability of AI agents to replicate state-of-the-art AI research.\\nProduct\\nMar 25, 2025\\nIntroducing 4o Image Generation\\nAt OpenAI, we have long believed image generation should be a primary capability of our language models. That’s why we’ve built our most advanced image generator yet into GPT‑4o. The result—image generation that is not only beautiful, but useful.\\nPublication\\nMar 25, 2025\\nAddendum to GPT-4o System Card: 4o image generation\\n4o image generation is a new, significantly more capable image generation approach than our earlier DALL·E 3 series of models. It can create photorealistic output. It can take images as inputs and transform them.\\nResearch\\nMar 21, 2025\\nEarly methods for studying affective use and emotional well-being on ChatGPT\\nAn OpenAI and MIT Media Lab Research collaboration.\\nRelease\\nMar 20, 2025\\nIntroducing next-generation audio models in the API\\nFor the first time, developers can also instruct the text-to-speech model to speak in a specific way—for example, “talk like a sympathetic customer service agent”—unlocking a new level of customization for voice agents.\\nPublication\\nMar 10, 2025\\nDetecting misbehavior in frontier reasoning models\\nFrontier reasoning models exploit loopholes when given the chance. We show we can detect exploits using an LLM to monitor their chains-of-thought. Penalizing their “bad thoughts” doesn’t stop the majority of misbehavior—it makes them hide their intent.\\nPublication\\nFeb 27, 2025\\nOpenAI GPT-4.5 System Card\\nWe’re releasing a research preview of OpenAI GPT‑4.5, our largest and most knowledgeable model yet.\\nRelease\\nFeb 27, 2025\\nIntroducing GPT-4.5\\nWe’re releasing a research preview of GPT‑4.5—our largest and best model for chat yet. GPT‑4.5 is a step forward in scaling up pre-training and post-training.\\nLoad more\\nOur Research\\nResearch Index\\nResearch Overview\\nResearch Residency\\nLatest Advancements\\nOpenAI o1\\nOpenAI o1-mini\\nGPT-4o\\nGPT-4o mini\\nSora\\nSafety\\nSafety Approach\\nSecurity & Privacy\\nChatGPT\\nExplore ChatGPT\\nTeam\\nEnterprise\\nEducation\\nPricing\\nDownload\\nSora\\nSora Overview\\nFeatures\\nPricing\\nSora log in\\n(opens in a new window)\\nAPI Platform\\nPlatform Overview\\nPricing\\nAPI log in\\n(opens in a new window)\\nDocumentation\\n(opens in a new window)\\nDeveloper Forum\\n(opens in a new window)\\nFor Business\\nOverview\\nCompany\\nAbout us\\nOur Charter\\nCareers\\nBrand\\nMore\\nNews\\nStories\\nHelp Center\\n(opens in a new window)\\nTerms & Policies\\nTerms of Use\\nPrivacy Policy\\nSecurity\\nOther Policies\\n(opens in a new window)\\n(opens in a new window)\\n(opens in a new window)\\n(opens in a new window)\\n(opens in a new window)\\n(opens in a new window)\\n(opens in a new window)\\nOpenAI © 2015–2025'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_for(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ad4eed94-aa96-4dcf-8d64-f16c7674f20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using OpenAI\n",
    "def summarize_openai(url):\n",
    "    website = Website(url)\n",
    "    response = openai.chat.completions.create(\n",
    "        model = \"gpt-4o-mini\",\n",
    "        messages = messages_for(website)\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d18dbe8c-8d3c-40d0-aef8-992f4dfdccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Gemini\n",
    "def summarize_gemini(url):\n",
    "    website = Website(url)\n",
    "    model = genai.GenerativeModel(\"gemini-1.5.flash\")\n",
    "    response = model.generate_content(website)\n",
    "\n",
    "    return respose.text\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e7393550-06c8-429e-abda-ea438a57feb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_summary(url):\n",
    "    # summary = summarize_openai(url)\n",
    "    summary = summarize_gemini(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0c943e3f-6049-468a-9c50-c4abbde66f0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not create `Blob`, expected `Blob`, `dict` or an `Image` type(`PIL.Image.Image` or `IPython.display.Image`).\nGot a: <class '__main__.Website'>\nValue: <__main__.Website object at 0x128f9c550>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdisplay_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttps://www.adt.com/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[62]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mdisplay_summary\u001b[39m\u001b[34m(url)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdisplay_summary\u001b[39m(url):\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# summary = summarize_openai(url)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     summary = \u001b[43msummarize_gemini\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     display(Markdown(summary))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36msummarize_gemini\u001b[39m\u001b[34m(url)\u001b[39m\n\u001b[32m      3\u001b[39m website = Website(url)\n\u001b[32m      4\u001b[39m model = genai.GenerativeModel(\u001b[33m\"\u001b[39m\u001b[33mgemini-1.5.flash\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m response = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwebsite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m respose.text\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM-based_projects/venv/lib/python3.11/site-packages/google/generativeai/generative_models.py:305\u001b[39m, in \u001b[36mGenerativeModel.generate_content\u001b[39m\u001b[34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[39m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m contents:\n\u001b[32m    303\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcontents must not be empty\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m305\u001b[39m request = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m    \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[43m=\u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtool_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m request.contents \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m request.contents[-\u001b[32m1\u001b[39m].role:\n\u001b[32m    314\u001b[39m     request.contents[-\u001b[32m1\u001b[39m].role = _USER_ROLE\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM-based_projects/venv/lib/python3.11/site-packages/google/generativeai/generative_models.py:154\u001b[39m, in \u001b[36mGenerativeModel._prepare_request\u001b[39m\u001b[34m(self, contents, generation_config, safety_settings, tools, tool_config)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    152\u001b[39m     tool_config = content_types.to_tool_config(tool_config)\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m contents = \u001b[43mcontent_types\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_contents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m generation_config = generation_types.to_generation_config_dict(generation_config)\n\u001b[32m    157\u001b[39m merged_gc = \u001b[38;5;28mself\u001b[39m._generation_config.copy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM-based_projects/venv/lib/python3.11/site-packages/google/generativeai/types/content_types.py:333\u001b[39m, in \u001b[36mto_contents\u001b[39m\u001b[34m(contents)\u001b[39m\n\u001b[32m    328\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    329\u001b[39m         \u001b[38;5;66;03m# If you get a TypeError here it's probably because that was a list\u001b[39;00m\n\u001b[32m    330\u001b[39m         \u001b[38;5;66;03m# of parts, not a list of contents, so fall back to `to_content`.\u001b[39;00m\n\u001b[32m    331\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m contents = [\u001b[43mto_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m contents\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM-based_projects/venv/lib/python3.11/site-packages/google/generativeai/types/content_types.py:299\u001b[39m, in \u001b[36mto_content\u001b[39m\u001b[34m(content)\u001b[39m\n\u001b[32m    296\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m protos.Content(parts=[to_part(part) \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m content])\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    298\u001b[39m     \u001b[38;5;66;03m# Maybe this is a Part?\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m299\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m protos.Content(parts=[\u001b[43mto_part\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM-based_projects/venv/lib/python3.11/site-packages/google/generativeai/types/content_types.py:264\u001b[39m, in \u001b[36mto_part\u001b[39m\u001b[34m(part)\u001b[39m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m protos.Part(function_response=part)\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    263\u001b[39m     \u001b[38;5;66;03m# Maybe it can be turned into a blob?\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m protos.Part(inline_data=\u001b[43mto_blob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpart\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/LLM-based_projects/venv/lib/python3.11/site-packages/google/generativeai/types/content_types.py:210\u001b[39m, in \u001b[36mto_blob\u001b[39m\u001b[34m(blob)\u001b[39m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(blob, Mapping):\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[32m    208\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not recognize the intended type of the `dict`\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[33m\"\u001b[39m\u001b[33mA content should have \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    209\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    211\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mCould not create `Blob`, expected `Blob`, `dict` or an `Image` type\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    212\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m(`PIL.Image.Image` or `IPython.display.Image`).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    213\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGot a: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(blob)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    214\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mValue: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mblob\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    215\u001b[39m )\n",
      "\u001b[31mTypeError\u001b[39m: Could not create `Blob`, expected `Blob`, `dict` or an `Image` type(`PIL.Image.Image` or `IPython.display.Image`).\nGot a: <class '__main__.Website'>\nValue: <__main__.Website object at 0x128f9c550>"
     ]
    }
   ],
   "source": [
    "display_summary(\"https://www.adt.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f035a95a-51c2-4a3e-8e58-81937877665e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
